{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "iraqi-alloy",
   "metadata": {},
   "source": [
    "## Stock Bot\n",
    "Okay Im gonna make a DIY stock trading, reinforcment learning bot on my own with preferably only tensorflow, numpy, and padas. I actually have no idea how to do that, sooo lets try it out!\n",
    "\n",
    "### Planning\n",
    "I need to have the following items built\n",
    "- the environment\n",
    "- the agent\n",
    "- memory for the agent\n",
    "- the policy for the agent\n",
    "- the neural net for the agent\n",
    "\n",
    "TODO: Train and wth is wrong with the probabilities contain nAn for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "significant-norway",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import yfinance as yf\n",
    "import gym_anytrading\n",
    "import rl\n",
    "from StockTradeEnv import FastTrainingStockTradeEnv\n",
    "from LowRegulationStockTradeEnv import LowRegulationStockTradeEnv\n",
    "import quantstats as qs\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback, EveryNTimesteps\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, Activation, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from stable_baselines3 import PPO, A2C\n",
    "from stable_baselines3.ppo.policies import MlpPolicy as MlpPolictPPO\n",
    "from stable_baselines3.a2c.policies import MlpPolicy as MlpPolictA2C\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv,SubprocVecEnv,VecEnv\n",
    "from Utilities import eval_model\n",
    "from Utilities import plot_history\n",
    "from LSTMPolicy import LSTMActorCriticPolicy,CustomLSTM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impaired-photograph",
   "metadata": {},
   "source": [
    "## Environment\n",
    "The environment will contain the observable variables:\n",
    "    -\n",
    "    -\n",
    "The environment will contain the avalible actions of:\n",
    "    -\n",
    "    -\n",
    "    -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cordless-singer",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryandu_1/miniforge3/envs/tfenv/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/Users/ryandu_1/miniforge3/envs/tfenv/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "# Parallel environments\n",
    "stks = ['kros','nflx']#,'tmus','adct','h','bngo','amzn','nio','fb','gme','work','irbt','upwk','fvrr','rdfn','bynd','etsy','pins','zg','roku','sq','pm','dis','nlok','bio','gbio']\n",
    "# env = DummyVecEnv([lambda: FastTrainingStockTradeEnv(ticker=stks[i],frame_bound=(100, 100000), window_size=10,initial_balance=25000,verbose=0,obs_dim=3) for i in range(len(stks))])\n",
    "env = DummyVecEnv([lambda: LowRegulationStockTradeEnv(ticker=stks[i],frame_bound=(100, 100000), window_size=10,initial_balance=25000,verbose=2) for i in range(len(stks))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "premier-heading",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'feature_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a46a2357c804>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfeatures_extractor_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel_ppo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPPO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MlpPolicy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpolicy_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge3/envs/tfenv/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, policy, env, learning_rate, n_steps, batch_size, n_epochs, gamma, gae_lambda, clip_range, clip_range_vf, ent_coef, vf_coef, max_grad_norm, use_sde, sde_sample_freq, target_kl, tensorboard_log, create_eval_env, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_init_setup_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tfenv/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36m_setup_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPPO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# Initialize schedules for policy/value clipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tfenv/lib/python3.8/site-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36m_setup_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mn_envs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_envs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         )\n\u001b[0;32m--> 114\u001b[0;31m         self.policy = self.policy_class(\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tfenv/lib/python3.8/site-packages/stable_baselines3/common/policies.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, observation_space, action_space, lr_schedule, net_arch, activation_fn, ortho_init, use_sde, log_std_init, full_std, sde_net_arch, use_expln, squash_output, features_extractor_class, features_extractor_kwargs, normalize_images, optimizer_class, optimizer_kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mortho_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mortho_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_extractor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_extractor_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_extractor_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'feature_dim'"
     ]
    }
   ],
   "source": [
    "policy_kwargs = dict(\n",
    "    features_extractor_class=CustomLSTM,\n",
    "    features_extractor_kwargs=dict(features_dim=2),\n",
    ")\n",
    "model_ppo = PPO('MlpPolicy', env, verbose=0,policy_kwargs=policy_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-patch",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_ppo=model_ppo.learn(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-philippines",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#PPO \n",
    "env = eval_model('kros',model_ppo,verbose=0)\n",
    "fig = plot_history(env.history,(22, 12)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-windsor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
